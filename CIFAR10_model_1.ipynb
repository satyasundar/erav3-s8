{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satyasundar/erav3-s8/blob/main/CIFAR10_model_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vX4JllxzOa-j"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torchvision.datasets import CIFAR10\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiIXRe_gA1kd",
        "outputId": "fd41c351-f329-42df-e3e0-290fb9b6cbe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "mean = [0.4914, 0.4822, 0.4465]\n",
        "std = [0.2470, 0.2435, 0.2616]\n",
        "\n",
        "train_transforms = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=0.1),\n",
        "    #A.RandomBrightnessContrast(p=0.2),\n",
        "    A.CoarseDropout(max_holes = 1, max_height=16, max_width=16, min_holes = 1, min_height=16, min_width=16, fill_value=(0.4914, 0.4822, 0.4465), mask_fill_value = None, p=0.1),\n",
        "    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "test_transforms = A.Compose([\n",
        "    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "class AlbumentationDataset(CIFAR10):\n",
        "    def __init__(self, root=\"./data\", train=True, download=True, transform=None):\n",
        "        super().__init__(root=root, train=train, download=download, transform=transform)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.data[index], self.targets[index]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(image=image)\n",
        "            image = transformed[\"image\"]\n",
        "\n",
        "        return image, label\n",
        "\n",
        "train = AlbumentationDataset(root='./data', train=True, download=True, transform=train_transforms)\n",
        "test = AlbumentationDataset(root='./data', train=False, download=True, transform=test_transforms)\n",
        "\n",
        "# Create DataLoader\n",
        "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-5_ZctIOa-l",
        "outputId": "7a57e62e-a558-42db-ecd2-f3a02c30730f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available? cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "SEED = 2\n",
        "\n",
        "# CUDA?\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"GPU Available?\", device)\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "# dataloader arguments - something you'll fetch these from cmdprmt\n",
        "dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=128)\n",
        "\n",
        "# train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
        "\n",
        "# test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)\n",
        "\n",
        "# Pretty table for collecting all the accuracy and loss parameters in a table\n",
        "log_table = PrettyTable()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-3iCQrGTOa-n"
      },
      "outputs": [],
      "source": [
        "dropout_value = 0.1\n",
        "# CNN Model\n",
        "class CIFAR10Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CIFAR10Model, self).__init__()\n",
        "\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            #input size : 3x32x32\n",
        "            # Block - 1, Layer - 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3, 3), stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(), # ouptput: 32, RF: 3\n",
        "            nn.Dropout(dropout_value),\n",
        "\n",
        "             # #Layer - 3\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(), # output: 32, RF: 7\n",
        "            nn.Dropout(dropout_value),\n",
        "\n",
        "            # Layer 2 - depthwise separable convolution\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), stride=1, padding=1, groups=32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1, 1), stride=1, padding=0),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(), #output: 32, RF: 5\n",
        "\n",
        "\n",
        "            # Stride-2 Convolution - downsampling\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(), # output: 16, RF: 9\n",
        "            nn.Dropout(dropout_value),\n",
        "        )\n",
        "\n",
        "        self.transition1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=16, kernel_size=(1, 1), padding=0, bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU() #output : 16, RF:9\n",
        "        )\n",
        "        self.convblock2 = nn.Sequential(\n",
        "\n",
        "            #Block - 2, Layer - 1\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(), #output: 16, RF: 13\n",
        "            nn.Dropout(dropout_value),\n",
        "\n",
        "            # Block - 2, Layer - 2\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(), #output: 16, RF: 17\n",
        "            nn.Dropout(dropout_value),\n",
        "\n",
        "            # stride = 2 convolution downsampling\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(), #output: 8, RF: 21\n",
        "            nn.Dropout(dropout_value),\n",
        "        )\n",
        "\n",
        "        self.transition2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=16, kernel_size=(1, 1), padding=0, bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU() #output:8, RF:21\n",
        "        )\n",
        "\n",
        "        self.convblock3 = nn.Sequential(\n",
        "\n",
        "            #Block - 3, Layer - 1\n",
        "\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(), #output: 8, RF: 29\n",
        "            nn.Dropout(dropout_value),\n",
        "\n",
        "            # Block - 3, Layer - 2\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(), #output: 8, RF: 37\n",
        "            nn.Dropout(dropout_value),\n",
        "\n",
        "             # Block - 3, Layer - 2 downsample here\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(), #output: 8, RF: 37\n",
        "            nn.Dropout(dropout_value),\n",
        "\n",
        "        )\n",
        "\n",
        "        self.transition3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=16, kernel_size=(1, 1), padding=0, bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.convblock4 = nn.Sequential(\n",
        "\n",
        "            #Block - 4, Layer Dilated Convolution\n",
        "            nn.Conv2d(in_channels=16, out_channels=64, kernel_size=(3, 3), stride=1, padding=2, dilation=2, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(), #output: 4, RF: 59\n",
        "        )\n",
        "\n",
        "        self.outputblock = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            #nn.AvgPool2d(kernel_size=4),\n",
        "            nn.Conv2d(in_channels=64, out_channels=10, kernel_size=(1, 1), padding=0, bias=False)\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.transition1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.transition2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.transition3(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.outputblock(x)\n",
        "        x = x.view(-1, 10)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLTTgAB6Oa-o",
        "outputId": "6fd6e92f-dae2-4224-ab63-5d5cefe0745a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             432\n",
            "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
            "              ReLU-3           [-1, 16, 32, 32]               0\n",
            "           Dropout-4           [-1, 16, 32, 32]               0\n",
            "            Conv2d-5           [-1, 32, 32, 32]           4,608\n",
            "       BatchNorm2d-6           [-1, 32, 32, 32]              64\n",
            "              ReLU-7           [-1, 32, 32, 32]               0\n",
            "           Dropout-8           [-1, 32, 32, 32]               0\n",
            "            Conv2d-9           [-1, 32, 32, 32]             320\n",
            "           Conv2d-10           [-1, 64, 32, 32]           2,112\n",
            "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
            "             ReLU-12           [-1, 64, 32, 32]               0\n",
            "           Conv2d-13           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-14           [-1, 64, 16, 16]             128\n",
            "             ReLU-15           [-1, 64, 16, 16]               0\n",
            "          Dropout-16           [-1, 64, 16, 16]               0\n",
            "           Conv2d-17           [-1, 16, 16, 16]           1,024\n",
            "      BatchNorm2d-18           [-1, 16, 16, 16]              32\n",
            "             ReLU-19           [-1, 16, 16, 16]               0\n",
            "           Conv2d-20           [-1, 32, 16, 16]           4,608\n",
            "      BatchNorm2d-21           [-1, 32, 16, 16]              64\n",
            "             ReLU-22           [-1, 32, 16, 16]               0\n",
            "          Dropout-23           [-1, 32, 16, 16]               0\n",
            "           Conv2d-24           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-25           [-1, 32, 16, 16]              64\n",
            "             ReLU-26           [-1, 32, 16, 16]               0\n",
            "          Dropout-27           [-1, 32, 16, 16]               0\n",
            "           Conv2d-28             [-1, 64, 8, 8]          18,432\n",
            "      BatchNorm2d-29             [-1, 64, 8, 8]             128\n",
            "             ReLU-30             [-1, 64, 8, 8]               0\n",
            "          Dropout-31             [-1, 64, 8, 8]               0\n",
            "           Conv2d-32             [-1, 16, 8, 8]           1,024\n",
            "      BatchNorm2d-33             [-1, 16, 8, 8]              32\n",
            "             ReLU-34             [-1, 16, 8, 8]               0\n",
            "           Conv2d-35             [-1, 32, 8, 8]           4,608\n",
            "      BatchNorm2d-36             [-1, 32, 8, 8]              64\n",
            "             ReLU-37             [-1, 32, 8, 8]               0\n",
            "          Dropout-38             [-1, 32, 8, 8]               0\n",
            "           Conv2d-39             [-1, 64, 8, 8]          18,432\n",
            "      BatchNorm2d-40             [-1, 64, 8, 8]             128\n",
            "             ReLU-41             [-1, 64, 8, 8]               0\n",
            "          Dropout-42             [-1, 64, 8, 8]               0\n",
            "           Conv2d-43             [-1, 64, 4, 4]          36,864\n",
            "      BatchNorm2d-44             [-1, 64, 4, 4]             128\n",
            "             ReLU-45             [-1, 64, 4, 4]               0\n",
            "          Dropout-46             [-1, 64, 4, 4]               0\n",
            "           Conv2d-47             [-1, 16, 4, 4]           1,024\n",
            "      BatchNorm2d-48             [-1, 16, 4, 4]              32\n",
            "             ReLU-49             [-1, 16, 4, 4]               0\n",
            "           Conv2d-50             [-1, 64, 4, 4]           9,216\n",
            "      BatchNorm2d-51             [-1, 64, 4, 4]             128\n",
            "             ReLU-52             [-1, 64, 4, 4]               0\n",
            "AdaptiveAvgPool2d-53             [-1, 64, 1, 1]               0\n",
            "           Conv2d-54             [-1, 10, 1, 1]             640\n",
            "================================================================\n",
            "Total params: 150,576\n",
            "Trainable params: 150,576\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 4.74\n",
            "Params size (MB): 0.57\n",
            "Estimated Total Size (MB): 5.33\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "cuda = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(cuda)\n",
        "model = CIFAR10Model().to(cuda)\n",
        "summary(model, input_size=(3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hXbZ5K2COa-o"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes.\n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    loss = criterion(y_pred, target)\n",
        "    #loss = F.nll_loss(y_pred, target)\n",
        "    train_losses.append(loss)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "\n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "    train_acc.append(100*correct/processed)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    criterion = nn.CrossEntropyLoss(reduction='sum')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()\n",
        "            #test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pszHAInXOa-o",
        "outputId": "55544954-4a89-4e8d-f1e7-a0a09d43d63a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model running on:  cuda\n",
            "EPOCH: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/391 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Loss=1.260455846786499 Batch_id=390 Accuracy=41.37: 100%|██████████| 391/391 [00:16<00:00, 23.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.6352, Accuracy: 4560/10000 (45.60%)\n",
            "\n",
            "EPOCH: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.2167580127716064 Batch_id=390 Accuracy=55.96: 100%|██████████| 391/391 [00:14<00:00, 26.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.0665, Accuracy: 6169/10000 (61.69%)\n",
            "\n",
            "EPOCH: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.2578181028366089 Batch_id=390 Accuracy=61.50: 100%|██████████| 391/391 [00:16<00:00, 24.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.0071, Accuracy: 6464/10000 (64.64%)\n",
            "\n",
            "EPOCH: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.8524954915046692 Batch_id=390 Accuracy=64.97: 100%|██████████| 391/391 [00:15<00:00, 25.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.0250, Accuracy: 6453/10000 (64.53%)\n",
            "\n",
            "EPOCH: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.8324249982833862 Batch_id=390 Accuracy=67.39: 100%|██████████| 391/391 [00:14<00:00, 26.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.9250, Accuracy: 6725/10000 (67.25%)\n",
            "\n",
            "EPOCH: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.9456140398979187 Batch_id=390 Accuracy=69.79: 100%|██████████| 391/391 [00:15<00:00, 25.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.7415, Accuracy: 7384/10000 (73.84%)\n",
            "\n",
            "EPOCH: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.9349117279052734 Batch_id=390 Accuracy=71.49: 100%|██████████| 391/391 [00:14<00:00, 26.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.8566, Accuracy: 7000/10000 (70.00%)\n",
            "\n",
            "EPOCH: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.9847301244735718 Batch_id=390 Accuracy=72.49: 100%|██████████| 391/391 [00:15<00:00, 25.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.7214, Accuracy: 7488/10000 (74.88%)\n",
            "\n",
            "EPOCH: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6765730977058411 Batch_id=390 Accuracy=74.05: 100%|██████████| 391/391 [00:15<00:00, 25.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6638, Accuracy: 7685/10000 (76.85%)\n",
            "\n",
            "EPOCH: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6368850469589233 Batch_id=390 Accuracy=74.81: 100%|██████████| 391/391 [00:14<00:00, 26.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6398, Accuracy: 7771/10000 (77.71%)\n",
            "\n",
            "EPOCH: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.545637309551239 Batch_id=390 Accuracy=75.50: 100%|██████████| 391/391 [00:16<00:00, 23.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6251, Accuracy: 7819/10000 (78.19%)\n",
            "\n",
            "EPOCH: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.7309141755104065 Batch_id=390 Accuracy=76.53: 100%|██████████| 391/391 [00:14<00:00, 26.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6467, Accuracy: 7789/10000 (77.89%)\n",
            "\n",
            "EPOCH: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5841480493545532 Batch_id=390 Accuracy=77.06: 100%|██████████| 391/391 [00:15<00:00, 25.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6176, Accuracy: 7876/10000 (78.76%)\n",
            "\n",
            "EPOCH: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.610268235206604 Batch_id=390 Accuracy=77.70: 100%|██████████| 391/391 [00:14<00:00, 26.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6018, Accuracy: 7909/10000 (79.09%)\n",
            "\n",
            "EPOCH: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6814438104629517 Batch_id=390 Accuracy=78.17: 100%|██████████| 391/391 [00:14<00:00, 26.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5509, Accuracy: 8113/10000 (81.13%)\n",
            "\n",
            "EPOCH: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6868442296981812 Batch_id=390 Accuracy=78.39: 100%|██████████| 391/391 [00:14<00:00, 26.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5833, Accuracy: 8035/10000 (80.35%)\n",
            "\n",
            "EPOCH: 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.7898532152175903 Batch_id=390 Accuracy=79.08: 100%|██████████| 391/391 [00:14<00:00, 26.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5843, Accuracy: 8040/10000 (80.40%)\n",
            "\n",
            "EPOCH: 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5668607354164124 Batch_id=390 Accuracy=79.05: 100%|██████████| 391/391 [00:14<00:00, 26.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5589, Accuracy: 8131/10000 (81.31%)\n",
            "\n",
            "EPOCH: 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.48928794264793396 Batch_id=390 Accuracy=79.66: 100%|██████████| 391/391 [00:15<00:00, 26.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5395, Accuracy: 8188/10000 (81.88%)\n",
            "\n",
            "EPOCH: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5538708567619324 Batch_id=390 Accuracy=80.09: 100%|██████████| 391/391 [00:14<00:00, 26.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5978, Accuracy: 7986/10000 (79.86%)\n",
            "\n",
            "EPOCH: 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6138526201248169 Batch_id=390 Accuracy=80.39: 100%|██████████| 391/391 [00:14<00:00, 26.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5429, Accuracy: 8092/10000 (80.92%)\n",
            "\n",
            "EPOCH: 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6080974340438843 Batch_id=390 Accuracy=80.37: 100%|██████████| 391/391 [00:15<00:00, 25.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5224, Accuracy: 8239/10000 (82.39%)\n",
            "\n",
            "EPOCH: 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5727637410163879 Batch_id=390 Accuracy=80.63: 100%|██████████| 391/391 [00:14<00:00, 26.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5109, Accuracy: 8276/10000 (82.76%)\n",
            "\n",
            "EPOCH: 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.47472482919692993 Batch_id=390 Accuracy=81.04: 100%|██████████| 391/391 [00:15<00:00, 25.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5217, Accuracy: 8226/10000 (82.26%)\n",
            "\n",
            "EPOCH: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5662104487419128 Batch_id=390 Accuracy=81.33: 100%|██████████| 391/391 [00:14<00:00, 26.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4765, Accuracy: 8363/10000 (83.63%)\n",
            "\n",
            "EPOCH: 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.42380914092063904 Batch_id=390 Accuracy=81.58: 100%|██████████| 391/391 [00:16<00:00, 24.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5138, Accuracy: 8274/10000 (82.74%)\n",
            "\n",
            "EPOCH: 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.45632320642471313 Batch_id=390 Accuracy=81.69: 100%|██████████| 391/391 [00:14<00:00, 26.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4855, Accuracy: 8376/10000 (83.76%)\n",
            "\n",
            "EPOCH: 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.45893198251724243 Batch_id=390 Accuracy=81.95: 100%|██████████| 391/391 [00:15<00:00, 26.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4971, Accuracy: 8341/10000 (83.41%)\n",
            "\n",
            "EPOCH: 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.577580988407135 Batch_id=390 Accuracy=82.07: 100%|██████████| 391/391 [00:14<00:00, 26.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4789, Accuracy: 8349/10000 (83.49%)\n",
            "\n",
            "EPOCH: 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5034649968147278 Batch_id=390 Accuracy=82.23: 100%|██████████| 391/391 [00:15<00:00, 26.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4842, Accuracy: 8366/10000 (83.66%)\n",
            "\n",
            "EPOCH: 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6198814511299133 Batch_id=390 Accuracy=82.18: 100%|██████████| 391/391 [00:14<00:00, 26.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5106, Accuracy: 8268/10000 (82.68%)\n",
            "\n",
            "EPOCH: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.48808568716049194 Batch_id=390 Accuracy=82.54: 100%|██████████| 391/391 [00:14<00:00, 26.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4603, Accuracy: 8422/10000 (84.22%)\n",
            "\n",
            "EPOCH: 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.3705518841743469 Batch_id=390 Accuracy=82.85: 100%|██████████| 391/391 [00:14<00:00, 26.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4497, Accuracy: 8466/10000 (84.66%)\n",
            "\n",
            "EPOCH: 34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.40688222646713257 Batch_id=390 Accuracy=82.79: 100%|██████████| 391/391 [00:14<00:00, 26.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4865, Accuracy: 8368/10000 (83.68%)\n",
            "\n",
            "EPOCH: 35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.42879390716552734 Batch_id=390 Accuracy=82.99: 100%|██████████| 391/391 [00:15<00:00, 26.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4702, Accuracy: 8416/10000 (84.16%)\n",
            "\n",
            "EPOCH: 36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.2693183720111847 Batch_id=390 Accuracy=83.30: 100%|██████████| 391/391 [00:14<00:00, 26.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4868, Accuracy: 8377/10000 (83.77%)\n",
            "\n",
            "EPOCH: 37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.452004998922348 Batch_id=390 Accuracy=83.32: 100%|██████████| 391/391 [00:14<00:00, 26.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4521, Accuracy: 8489/10000 (84.89%)\n",
            "\n",
            "EPOCH: 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.603645384311676 Batch_id=390 Accuracy=83.37: 100%|██████████| 391/391 [00:14<00:00, 26.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4501, Accuracy: 8479/10000 (84.79%)\n",
            "\n",
            "EPOCH: 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.552642285823822 Batch_id=390 Accuracy=83.46: 100%|██████████| 391/391 [00:15<00:00, 25.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4470, Accuracy: 8474/10000 (84.74%)\n",
            "\n",
            "EPOCH: 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.39833930134773254 Batch_id=390 Accuracy=83.77: 100%|██████████| 391/391 [00:16<00:00, 23.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4671, Accuracy: 8453/10000 (84.53%)\n",
            "\n",
            "EPOCH: 41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4198873043060303 Batch_id=390 Accuracy=83.72: 100%|██████████| 391/391 [00:14<00:00, 26.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4467, Accuracy: 8477/10000 (84.77%)\n",
            "\n",
            "EPOCH: 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4761854112148285 Batch_id=390 Accuracy=83.71: 100%|██████████| 391/391 [00:14<00:00, 26.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4487, Accuracy: 8491/10000 (84.91%)\n",
            "\n",
            "EPOCH: 43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.28720229864120483 Batch_id=390 Accuracy=84.20: 100%|██████████| 391/391 [00:14<00:00, 26.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4406, Accuracy: 8504/10000 (85.04%)\n",
            "\n",
            "EPOCH: 44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.466238409280777 Batch_id=390 Accuracy=84.15: 100%|██████████| 391/391 [00:14<00:00, 26.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4404, Accuracy: 8535/10000 (85.35%)\n",
            "\n",
            "EPOCH: 45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.37305712699890137 Batch_id=390 Accuracy=84.16: 100%|██████████| 391/391 [00:14<00:00, 26.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4427, Accuracy: 8495/10000 (84.95%)\n",
            "\n",
            "EPOCH: 46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5065498948097229 Batch_id=390 Accuracy=84.06: 100%|██████████| 391/391 [00:15<00:00, 26.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4446, Accuracy: 8513/10000 (85.13%)\n",
            "\n",
            "EPOCH: 47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4016569256782532 Batch_id=390 Accuracy=84.44: 100%|██████████| 391/391 [00:15<00:00, 25.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4517, Accuracy: 8481/10000 (84.81%)\n",
            "\n",
            "EPOCH: 48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.2598184645175934 Batch_id=390 Accuracy=84.40: 100%|██████████| 391/391 [00:14<00:00, 26.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4251, Accuracy: 8580/10000 (85.80%)\n",
            "\n",
            "EPOCH: 49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.36957162618637085 Batch_id=390 Accuracy=84.43: 100%|██████████| 391/391 [00:14<00:00, 26.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4303, Accuracy: 8567/10000 (85.67%)\n",
            "\n",
            "EPOCH: 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.46526843309402466 Batch_id=390 Accuracy=84.66: 100%|██████████| 391/391 [00:14<00:00, 26.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4422, Accuracy: 8543/10000 (85.43%)\n",
            "\n",
            "+-------+-------------------+---------------+-------+---------------+-----------+\n",
            "| Epoch | Training Accuracy | Test Accuracy |  Diff | Training Loss | Test Loss |\n",
            "+-------+-------------------+---------------+-------+---------------+-----------+\n",
            "|   1   |       41.37%      |     45.60%    | -4.23 |     1.2605    |   1.6352  |\n",
            "|   2   |       55.96%      |     61.69%    | -5.73 |     1.2168    |   1.0665  |\n",
            "|   3   |       61.50%      |     64.64%    | -3.14 |     1.2578    |   1.0071  |\n",
            "|   4   |       64.97%      |     64.53%    |  0.44 |     0.8525    |   1.0250  |\n",
            "|   5   |       67.39%      |     67.25%    |  0.14 |     0.8324    |   0.9250  |\n",
            "|   6   |       69.79%      |     73.84%    | -4.05 |     0.9456    |   0.7415  |\n",
            "|   7   |       71.49%      |     70.00%    |  1.49 |     0.9349    |   0.8566  |\n",
            "|   8   |       72.49%      |     74.88%    | -2.39 |     0.9847    |   0.7214  |\n",
            "|   9   |       74.05%      |     76.85%    | -2.80 |     0.6766    |   0.6638  |\n",
            "|   10  |       74.81%      |     77.71%    | -2.90 |     0.6369    |   0.6398  |\n",
            "|   11  |       75.50%      |     78.19%    | -2.69 |     0.5456    |   0.6251  |\n",
            "|   12  |       76.53%      |     77.89%    | -1.36 |     0.7309    |   0.6467  |\n",
            "|   13  |       77.06%      |     78.76%    | -1.70 |     0.5841    |   0.6176  |\n",
            "|   14  |       77.70%      |     79.09%    | -1.39 |     0.6103    |   0.6018  |\n",
            "|   15  |       78.17%      |     81.13%    | -2.96 |     0.6814    |   0.5509  |\n",
            "|   16  |       78.39%      |     80.35%    | -1.96 |     0.6868    |   0.5833  |\n",
            "|   17  |       79.08%      |     80.40%    | -1.32 |     0.7899    |   0.5843  |\n",
            "|   18  |       79.05%      |     81.31%    | -2.26 |     0.5669    |   0.5589  |\n",
            "|   19  |       79.66%      |     81.88%    | -2.22 |     0.4893    |   0.5395  |\n",
            "|   20  |       80.09%      |     79.86%    |  0.23 |     0.5539    |   0.5978  |\n",
            "|   21  |       80.39%      |     80.92%    | -0.53 |     0.6139    |   0.5429  |\n",
            "|   22  |       80.37%      |     82.39%    | -2.02 |     0.6081    |   0.5224  |\n",
            "|   23  |       80.63%      |     82.76%    | -2.13 |     0.5728    |   0.5109  |\n",
            "|   24  |       81.04%      |     82.26%    | -1.22 |     0.4747    |   0.5217  |\n",
            "|   25  |       81.33%      |     83.63%    | -2.30 |     0.5662    |   0.4765  |\n",
            "|   26  |       81.58%      |     82.74%    | -1.16 |     0.4238    |   0.5138  |\n",
            "|   27  |       81.69%      |     83.76%    | -2.07 |     0.4563    |   0.4855  |\n",
            "|   28  |       81.95%      |     83.41%    | -1.46 |     0.4589    |   0.4971  |\n",
            "|   29  |       82.07%      |     83.49%    | -1.42 |     0.5776    |   0.4789  |\n",
            "|   30  |       82.23%      |     83.66%    | -1.43 |     0.5035    |   0.4842  |\n",
            "|   31  |       82.18%      |     82.68%    | -0.50 |     0.6199    |   0.5106  |\n",
            "|   32  |       82.54%      |     84.22%    | -1.68 |     0.4881    |   0.4603  |\n",
            "|   33  |       82.85%      |     84.66%    | -1.81 |     0.3706    |   0.4497  |\n",
            "|   34  |       82.79%      |     83.68%    | -0.89 |     0.4069    |   0.4865  |\n",
            "|   35  |       82.99%      |     84.16%    | -1.17 |     0.4288    |   0.4702  |\n",
            "|   36  |       83.30%      |     83.77%    | -0.47 |     0.2693    |   0.4868  |\n",
            "|   37  |       83.32%      |     84.89%    | -1.57 |     0.4520    |   0.4521  |\n",
            "|   38  |       83.37%      |     84.79%    | -1.42 |     0.6036    |   0.4501  |\n",
            "|   39  |       83.46%      |     84.74%    | -1.28 |     0.5526    |   0.4470  |\n",
            "|   40  |       83.77%      |     84.53%    | -0.76 |     0.3983    |   0.4671  |\n",
            "|   41  |       83.72%      |     84.77%    | -1.05 |     0.4199    |   0.4467  |\n",
            "|   42  |       83.71%      |     84.91%    | -1.20 |     0.4762    |   0.4487  |\n",
            "|   43  |       84.20%      |     85.04%    | -0.84 |     0.2872    |   0.4406  |\n",
            "|   44  |       84.15%      |     85.35%    | -1.20 |     0.4662    |   0.4404  |\n",
            "|   45  |       84.16%      |     84.95%    | -0.79 |     0.3731    |   0.4427  |\n",
            "|   46  |       84.06%      |     85.13%    | -1.07 |     0.5065    |   0.4446  |\n",
            "|   47  |       84.44%      |     84.81%    | -0.37 |     0.4017    |   0.4517  |\n",
            "|   48  |       84.40%      |     85.80%    | -1.40 |     0.2598    |   0.4251  |\n",
            "|   49  |       84.43%      |     85.67%    | -1.24 |     0.3696    |   0.4303  |\n",
            "|   50  |       84.66%      |     85.43%    | -0.77 |     0.4653    |   0.4422  |\n",
            "+-------+-------------------+---------------+-------+---------------+-----------+\n"
          ]
        }
      ],
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "print(\"model running on: \", device)\n",
        "log_table = PrettyTable()\n",
        "log_table.field_names = [\"Epoch\", \"Training Accuracy\", \"Test Accuracy\", \"Diff\", \"Training Loss\", \"Test Loss\"]\n",
        "\n",
        "model =  CIFAR10Model().to(device)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "scheduler = StepLR(optimizer, step_size=6, gamma=0.1)\n",
        "\n",
        "EPOCHS = 50\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"EPOCH:\", epoch+1)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    #scheduler.step()\n",
        "    test(model, device, test_loader)\n",
        "    log_table.add_row([epoch+1, f\"{train_acc[-1]:.2f}%\", f\"{test_acc[-1]:.2f}%\", f\"{float(train_acc[-1]) - float(test_acc[-1]):.2f}\" ,f\"{train_losses[-1]:.4f}\", f\"{test_losses[-1]:.4f}\"])\n",
        "print(log_table)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0kqU8zfouC3n"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}